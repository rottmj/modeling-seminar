{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6433b833",
   "metadata": {},
   "source": [
    "## Training f√ºr das Cut in Szenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74665c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import environment.test_env as Env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent.ddpg_tf2 as ddpg_tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ddpg_tf2.Agent((2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e72e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_list = []\n",
    "returns_list = []\n",
    "steps_list = []\n",
    "init_values = []\n",
    "modes = []\n",
    "velocities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a832d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 150\n",
    "score_history = []\n",
    "old_score = 0\n",
    "all_steps = 0\n",
    "i = 1\n",
    "\n",
    "while all_steps < 500000:\n",
    "    initial_speed_ego = np.random.uniform(low = 18.0, high = 30.0) \n",
    "    initial_speed_lead = np.random.uniform(low = 20.0, high = 28.0)\n",
    "    inital_speed_goal = np.random.uniform(low = 20.0, high = 28.0)\n",
    "    initial_gap = np.random.uniform(low = 25.0, high = 60.0)\n",
    "    initial_safety_gap = initial_speed_lead * 3.6 / 2\n",
    "    \n",
    "    init_values.append([initial_gap, initial_safety_gap, initial_speed_ego, initial_speed_lead])\n",
    "\n",
    "    env = Env.VehicleEnvironment(initial_speed_ego, initial_speed_lead, initial_gap, initial_safety_gap)\n",
    "    observation = np.array(env.get_state())\n",
    "\n",
    "    done = False\n",
    "    score = 0\n",
    "    steps = 0\n",
    "    vs = []\n",
    "    \n",
    "    for j in range(200):\n",
    "        vs.append(env.ego_velocity)\n",
    "        all_steps += 1\n",
    "        steps += 1\n",
    "        action = agent.choose_action(observation)\n",
    "        action_ = action.numpy()[0]\n",
    "        observation_, reward, done = env.step(action_, j)\n",
    "        score += reward\n",
    "        observation_ = np.array([observation_])\n",
    "        reward = np.array([[reward]])\n",
    "        done = np.array([[done]])\n",
    "        agent.remember(observation, action, reward, observation_, done)\n",
    "        agent.learn()\n",
    "        observation = np.array(observation_[0])\n",
    "        rewards_list.append(reward)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    # save data \n",
    "    returns_list.append(score)\n",
    "    steps_list.append(steps)\n",
    "    modes.append(env.mode)\n",
    "    velocities.append(vs)\n",
    "    \n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score # score statt avg_score\n",
    "        agent.save_models()\n",
    "\n",
    "    print('episode ', i, 'score %.1f' % score, 'avg score %.1f' % avg_score)\n",
    "    i += 1\n",
    "    print('steps: ', steps)\n",
    "    print(all_steps/500000, \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8fa78",
   "metadata": {},
   "source": [
    "## Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocities = []\n",
    "accels = []\n",
    "gaps = []\n",
    "velocities_lead = []\n",
    "safety_gaps = []\n",
    "initial_speed_ego = np.random.uniform(low = 18.0, high = 30.0) \n",
    "initial_speed_lead = np.random.uniform(low = 20.0, high = 28.0)  \n",
    "initial_gap = np.random.uniform(low = 25.0, high = 60.0)\n",
    "initial_safety_gap = initial_speed_lead * 3.6 / 2\n",
    "\n",
    "print(\"-----Initial Values-----\")\n",
    "print(\"gap: \", initial_gap)\n",
    "print(\"safety gap: \", initial_safety_gap)\n",
    "print(\"speed ego: \", initial_speed_ego)\n",
    "print(\"speed lead: \", initial_speed_lead)\n",
    "\n",
    "env = Env.VehicleEnvironment(initial_speed_ego, initial_speed_lead, initial_gap, initial_safety_gap)\n",
    "print(\"-----Mode------\")\n",
    "print(env.mode)\n",
    "# env.reset()\n",
    "observation = np.array(env.get_state())\n",
    "done = False\n",
    "score = 0\n",
    "for j in range(200):\n",
    "        #print(observation)\n",
    "        action = agent.choose_action(observation, True)\n",
    "        action_ = action.numpy()[0]\n",
    "        observation_, reward, done = env.step(action_, j)\n",
    "        #print(observation_, reward, done)\n",
    "        #print(action_)\n",
    "        #print(env.get_state())\n",
    "        velocities.append(env.ego_velocity)\n",
    "        accels.append(action_)\n",
    "        gaps.append(env.gap)\n",
    "        safety_gaps.append(env.safety_gap)\n",
    "        score += reward\n",
    "        observation = np.array(observation_)\n",
    "        #print(observation)\n",
    "        velocities_lead.append(env.lead_velocity)\n",
    "        if done:\n",
    "            break\n",
    "print(\"-----score-----\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc99014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ego Geschwindigkeit\n",
    "utils.plot_speed(velocities, \"graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f858e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead Geschwindigkeit\n",
    "utils.plot_speed(velocities_lead, \"graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcd7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ego Beschleunigung\n",
    "utils.plot_acceleration(accels, \"graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abweichung zum Optimalabstand\n",
    "g = []\n",
    "for i in range(200):\n",
    "    g.append(gaps[i] - safety_gaps[i])\n",
    "utils.plot_gap(g, \"graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2116e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns\n",
    "utils.plot_return(returns_list, \"graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae75ca2",
   "metadata": {},
   "source": [
    "## Daten speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509652d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('steps.pkl', 'wb') as file:\n",
    "    pickle.dump(steps_list, file)\n",
    "    \n",
    "with open('rewards.pkl', 'wb') as file:\n",
    "    pickle.dump(rewards_list, file)\n",
    "\n",
    "with open('returns.pkl', 'wb') as file:\n",
    "    pickle.dump(returns_list, file)\n",
    "    \n",
    "with open('buffer.pkl', 'wb') as file:\n",
    "    pickle.dump(agent.memory, file)\n",
    "    \n",
    "with open('init.pkl', 'wb') as file:\n",
    "    pickle.dump(init_values, file)\n",
    "    \n",
    "with open('modes.pkl', 'wb') as file:\n",
    "    pickle.dump(modes, file)\n",
    "    \n",
    "with open('velocities.pkl', 'wb') as file:\n",
    "    pickle.dump(velocities, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.target_actor.save_weights(\"last_taractor.h5\")\n",
    "agent.actor.save_weights(\"last_actor.h5\")\n",
    "agent.critic.save_weights(\"last_critic.h5\")\n",
    "agent.target_critic.save_weights(\"last_tarcritic.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
